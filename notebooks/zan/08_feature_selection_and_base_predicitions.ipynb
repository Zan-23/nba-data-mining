{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a9af66",
   "metadata": {},
   "source": [
    "# Feature selection and intial predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b103e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "from datetime import timedelta\n",
    "\n",
    "sys.path.insert(0, \"./../../\")\n",
    "\n",
    "# from src.preprocessing.feature_preparation import prepare_features_for_season_based_predictions\n",
    "from src.preprocessing.DataPreparator import DataPreparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daace820",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p = DataPreparator()\n",
    "all_games = data_p.get_games_df()\n",
    "\n",
    "# home team wins in 60% of the cases\n",
    "display(all_games[\"home_win\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fac41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# for the actual train set all_games.iloc[:round(len(all_games.index) * 0.8)][\"home_win\"].mean()\n",
    "display(all_games)\n",
    "\n",
    "with open(\"tmp_f_file.pickle\", \"wb\") as file:\n",
    "        pickle.dump(all_games, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c7c82",
   "metadata": {},
   "source": [
    "['home_recent_team_rebound', 'home_recent_team_turnover', 'home_recent_subs', 'home_recent_timeout', 'home_recent_jump_balls_won', 'home_recent_ejection', 'home_recent_team_ejection', 'home_recent_scoring_leader', 'home_recent_scoring_leader_points', 'home_recent_made_max_shot_distance', 'home_recent_made_min_shot_distance', 'home_recent_made_mean_shot_distance'] not in index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f931c",
   "metadata": {},
   "source": [
    "Base line for predictions is 0.597 -> which is ~60%, that means if we predict that each game will be won by the home team we are correct in 60% of cases. Any improvements over 60% are actual benefits of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data_p.prepare_data_splits(\"2017-2018\")\n",
    "display(x_train[:3], len(x_train))\n",
    "display(y_train[:3], len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3acff7",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "Select and transform only neccesary features for the model.\n",
    "   \n",
    "https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = all_games.corr()\n",
    "home_win_s = cor[\"home_win\"].abs().sort_values(ascending=False)\n",
    "display(home_win_s[:5])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=home_win_s, y=home_win_s.index))\n",
    "\n",
    "# Still need to test and determine best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a2df6",
   "metadata": {},
   "source": [
    "\n",
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# max_depth=100\n",
    "r_forest = RandomForestRegressor(n_estimators=150, criterion='squared_error', \n",
    "                                 random_state=42, max_depth=13)\n",
    "r_forest.fit(x_train, y_train)\n",
    "\n",
    "# evaluate on train data set ->> overfitting but just to see the accuracy\n",
    "print(\"Starting predictions ...\")\n",
    "y_pred_train = []\n",
    "for row in x_train:\n",
    "    y_pred_train.append(round(r_forest.predict([row])[0]))\n",
    "    \n",
    "print(f\"Accuracy on the train set is: {accuracy_score(y_train, y_pred_train, normalize=True) * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d876e",
   "metadata": {},
   "source": [
    "Evaluation on the train set yield an accuracy of 100% which means model can overfit to the given data correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on the test data set!\")\n",
    "\n",
    "y_pred_test = []\n",
    "for row in x_test:\n",
    "    y_pred_test.append(round(r_forest.predict([row])[0]))\n",
    "    \n",
    "print(f\"Accuracy on the train set is: {accuracy_score(y_test, y_pred_test, normalize=True) * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d4e63",
   "metadata": {},
   "source": [
    "For the \"wrong\" data points which encapsulate future data the model cchieves around 83% prediction accuracy on the test data set when the split is of size 0.8, 0.1 and 0.1. And 82% if the data is lowered to 82%.\n",
    "For the right data points, the features of which are based on a running average of values in the previous games the model achives accuracy from 62 to 72% which is 20% better than the baseline prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "precision, recall, f1, _s = precision_recall_fscore_support(y_test, y_pred_test, average='macro')\n",
    "print(precision, recall, f1)\n",
    "\n",
    "cmp_ht = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test))\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "plt.rc(\"font\", size=30)\n",
    "cmp_ht.plot(ax=ax)\n",
    "plt.savefig(\"conf_matrix_rf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f426b09",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Evaluating the features on SVM which should be home suited to this use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58682448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "# Features should be scaled before using SVM!\n",
    "# ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "svm_p = svm.SVC(kernel=\"linear\", C=0.5, random_state=42)\n",
    "svm_p.fit(x_train, y_train)\n",
    "\n",
    "# evaluate on train data set ->> overfitting but just to see the accuracy\n",
    "print(\"Starting predictions ...\")\n",
    "y_pred_train = []\n",
    "for row in x_train:\n",
    "    y_pred_train.append(round(svm_p.predict([row])[0]))\n",
    "    \n",
    "print(f\"Accuracy on the train set is: {accuracy_score(y_train, y_pred_train, normalize=True) * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a6b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on the test data set!\")\n",
    "\n",
    "y_svm_pred_test = []\n",
    "for row in x_test:\n",
    "    y_svm_pred_test.append(round(svm_p.predict([row])[0]))\n",
    "    \n",
    "print(f\"Accuracy on the train set is: {accuracy_score(y_test, y_svm_pred_test, normalize=True) * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b53dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _s = precision_recall_fscore_support(y_test, y_svm_pred_test, average='macro')\n",
    "print(precision, recall, f1)\n",
    "\n",
    "cmp_ht = ConfusionMatrixDisplay(confusion_matrix(y_test, y_svm_pred_test))\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.rc(\"font\", size=30)\n",
    "cmp_ht.plot(ax=ax)\n",
    "plt.savefig(\"conf_matrix_svm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf65fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nba_play_by_play_data_mining]",
   "language": "python",
   "name": "conda-env-nba_play_by_play_data_mining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
